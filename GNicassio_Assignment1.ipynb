{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMzTkBCLx/T6LXLGtVb1S30",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicas83/ispr22/blob/main/GNicassio_Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyCB4wg4Ym6R"
      },
      "outputs": [],
      "source": [
        "pip install hmmlearn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 1\n",
        "\n",
        "Fit an Hidden Markov Model with Gaussian emissions to the data in DSET1: it is sufficient to focus on the “Appliances” and “Lights” columns of the dataset which measure the energy consumption of appliances and lights, respectively, across a period of 4.5 months. Consider the two columns in isolation, i.e. train two separate HMM, one for appliances and one for light.  Experiment with HMMs with a varying number of hidden states (e.g. at least 2, 3 and 4). Once trained the HMMs, perform Viterbi on a reasonably sized subsequence (e.g. 1 month of data) and plot the timeseries data highlighting (e.g. with different colours) the hidden state assigned to each timepoint by the Viterbi algorithm.  Then, fit a single HMM emitting both appliance and light with the same model and repeat the Viterbi assessment. Confront the two results."
      ],
      "metadata": {
        "id": "L6ZGqQ-qasxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plot\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from hmmlearn import hmm\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "Da5KFLtCZCxy"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/energydata_complete.csv')\n",
        "# convert string date into dateformat\n",
        "data[\"date\"] = pd.to_datetime(data[\"date\"])"
      ],
      "metadata": {
        "id": "W7UazO2un-Fw"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Considering the Hidden Markov Model for the Appliances with respectively 2,3 and 4 hidden states.\n",
        "For each experiment is important to split the dataset into training set and validation set (80-20) to ensure that the model is fitting well (use the score() function to extract the best model).\n",
        "Then make the assumption on the n_component variable that means make assumption on the states of the HMM (high, low, medium for example).\n",
        "Non c'è il set di model parameters iniziale (pigreco, A e theta), quindi devo appliare l'algoritmo di EM per individuarle e ricomputare con Viterbi."
      ],
      "metadata": {
        "id": "znuqlqZgvOWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting the initial dataset considering only datetime and appliances\n",
        "#data = data[data[\"date\"] <= pd.to_datetime(\"2016-02-02 \")] \n",
        "figure, ax = plot.subplots(figsize=(15,15))\n",
        "ax.plot(data[\"date\"], data[\"Appliances\"])\n",
        "ax.autoscale(enable=True, axis=\"x\", tight=True)\n",
        "plot.show()"
      ],
      "metadata": {
        "id": "it_cNhVpBwFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting the initial dataset considering only datetime and lights\n",
        "figure, ax = plot.subplots(figsize=(15,15))\n",
        "ax.plot(data[\"date\"], data[\"lights\"])\n",
        "ax.autoscale(enable=True, axis=\"x\", tight=True)\n",
        "plot.show()"
      ],
      "metadata": {
        "id": "_pMItQzOF0pP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split the array into training and test set\n",
        "x_train, x_test = train_test_split(data, shuffle=True)\n",
        "print (\"Lunghezza train\")\n",
        "print (len(x_train))\n",
        "print (\"Lunghezza test\")\n",
        "print (len(x_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amVA_g-z3Ier",
        "outputId": "5c45b0d4-a29e-43ff-c231-2c59b036011a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lunghezza train\n",
            "14801\n",
            "Lunghezza test\n",
            "4934\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# build and fit an HMM on the first column \"Appliances\"\n",
        "X_fit = x_train[['Appliances']].values\n",
        "X_predict = x_test[['Appliances']].values\n",
        "\n",
        "X_fit = np.sort(X_fit)\n",
        "# hidden states= 3\n",
        "model = hmm.GaussianHMM(n_components= 4, covariance_type=\"full\", n_iter = 1000)\n",
        "model.fit(X_fit)\n",
        "print (\"model score:\") \n",
        "print (model.decode(X_fit, algorithm='viterbi'))\n",
        "\n",
        "Z = model.predict(X_predict)\n",
        "states = pd.unique(Z)\n",
        "\n",
        "print (\"Printing states:\")\n",
        "print (states)\n",
        "\n",
        "print (\"Start probability\")\n",
        "print (model.startprob_)\n",
        "\n",
        "print (\"Transition Matrix\")\n",
        "print (model.transmat_)\n",
        "\n",
        "print (\"Gaussian distribution means:\")\n",
        "print (model.means_)\n",
        "\n",
        "print(\"\\nGaussian distribution covariances:\")\n",
        "print(model.covars_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJuJBqaje8gy",
        "outputId": "0e0199fb-d249-45e8-df01-a1da52fca6d8"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model score:\n",
            "(-79192.19103207394, array([3, 2, 1, ..., 1, 1, 3]))\n",
            "Printing states:\n",
            "[3 1 0 2]\n",
            "Start probability\n",
            "[1.41867298e-274 2.59015983e-285 0.00000000e+000 1.00000000e+000]\n",
            "Transition Matrix\n",
            "[[4.68018335e-01 6.61055295e-03 1.67550321e-02 5.08616080e-01]\n",
            " [1.82345462e-01 4.01956842e-01 1.37813461e-01 2.77884235e-01]\n",
            " [1.91062344e-01 4.22890510e-01 1.15251153e-01 2.70795992e-01]\n",
            " [5.17314028e-07 7.07934115e-01 2.07430349e-01 8.46350192e-02]]\n",
            "Gaussian distribution means:\n",
            "[[ 51.34446845]\n",
            " [ 82.77850001]\n",
            " [306.23675124]\n",
            " [ 51.24739439]]\n",
            "\n",
            "Gaussian distribution covariances:\n",
            "[[[  111.90334888]]\n",
            "\n",
            " [[  905.46203689]]\n",
            "\n",
            " [[25422.62596305]]\n",
            "\n",
            " [[  102.17625067]]]\n"
          ]
        }
      ]
    }
  ]
}